{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYvkrjF0XR0G",
        "outputId": "b3787a1a-b5e1-4e0a-839f-368e652c7c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "g_lA_j1iXX_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X1Fps5PbTl_",
        "outputId": "2bad4aff-be81-4c7a-a80f-48d5988503bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqjUlFIJXN2l",
        "outputId": "ae435505-388e-4ac0-9973-294fd5beb381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading LJSpeech checkpoint: /content/drive/MyDrive/266/Tacotron_ft/checkpoint/pytorch_model.bin\n",
            "Missing keys: ['decoder.attention.decoder_proj.linear.weight', 'decoder.attention.decoder_proj.linear.bias', 'decoder.attention.encoder_proj.linear.weight', 'decoder.attention.location_layer.conv.conv.weight', 'decoder.attention.location_layer.proj.linear.weight', 'decoder.emotion_embedding.weight', 'decoder.emotion_to_hidden.weight', 'decoder.emotion_to_hidden.bias', 'emotion_embedding.weight', 'emotion_to_hidden.weight', 'emotion_to_hidden.bias']\n",
            "Unexpected keys: ['decoder.attention.in_proj.linear.weight', 'decoder.attention.in_proj.linear.bias', 'decoder.attention.enc_proj.linear.weight', 'decoder.attention.what_have_i_said.conv.conv.weight', 'decoder.attention.what_have_i_said.proj.linear.weight']\n",
            "Trainable parameters: 22670657\n",
            "/content/drive/MyDrive/266/Tacotron_ft/dataset.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(t) for t in texts],\n",
            "Epoch 0 train loss: 0.4661\n",
            "Epoch 0 val loss: 0.3517\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_0.pt\n",
            "Epoch 1 train loss: 0.3781\n",
            "Epoch 1 val loss: 0.3230\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_1.pt\n",
            "Epoch 2 train loss: 0.3570\n",
            "Epoch 2 val loss: 0.3075\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_2.pt\n",
            "Epoch 3 train loss: 0.3448\n",
            "Epoch 3 val loss: 0.2988\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_3.pt\n",
            "Epoch 4 train loss: 0.3368\n",
            "Epoch 4 val loss: 0.2920\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_4.pt\n",
            "Epoch 5 train loss: 0.3304\n",
            "Epoch 5 val loss: 0.2869\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_5.pt\n",
            "Epoch 6 train loss: 0.3255\n",
            "Epoch 6 val loss: 0.2834\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_6.pt\n",
            "Epoch 7 train loss: 0.3210\n",
            "Epoch 7 val loss: 0.2807\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_7.pt\n",
            "Epoch 8 train loss: 0.3173\n",
            "Epoch 8 val loss: 0.2775\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_8.pt\n",
            "Epoch 9 train loss: 0.3138\n",
            "Epoch 9 val loss: 0.2759\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_9.pt\n",
            "Epoch 10 train loss: 0.3109\n",
            "Epoch 10 val loss: 0.2737\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_10.pt\n",
            "Epoch 11 train loss: 0.3076\n",
            "Epoch 11 val loss: 0.2716\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_11.pt\n",
            "Epoch 12 train loss: 0.3051\n",
            "Epoch 12 val loss: 0.2700\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_12.pt\n",
            "Epoch 13 train loss: 0.3021\n",
            "Epoch 13 val loss: 0.2682\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_13.pt\n",
            "Epoch 14 train loss: 0.2991\n",
            "Epoch 14 val loss: 0.2661\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_14.pt\n",
            "Epoch 15 train loss: 0.2959\n",
            "Epoch 15 val loss: 0.2636\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_15.pt\n",
            "Epoch 16 train loss: 0.2929\n",
            "Epoch 16 val loss: 0.2623\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_16.pt\n",
            "Epoch 17 train loss: 0.2903\n",
            "Epoch 17 val loss: 0.2610\n",
            "Saved: work_dir/taco2_emov_finetune/tacotron2_emov_epoch_17.pt\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/266/Tacotron_ft/train.py \\\n",
        "  --lj_checkpoint /content/drive/MyDrive/266/Tacotron_ft/checkpoint/pytorch_model.bin \\\n",
        "  --train_manifest /content/drive/MyDrive/266/Tacotron2/emovdb/train_metadata.csv \\\n",
        "  --val_manifest /content/drive/MyDrive/266/Tacotron2/emovdb/test_metadata.csv \\\n",
        "  --out_dir work_dir/taco2_emov_finetune/ \\\n",
        "  --epochs 40 \\\n",
        "  --batch_size 32 \\\n",
        "  --lr 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv work_dir/taco2_emov_finetune/tacotron2_emov_epoch_40.pt /content/drive/MyDrive/266/Tacotron_ft/work_dir"
      ],
      "metadata": {
        "id": "qqw7USpqX-qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7YnNxvq_JDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
